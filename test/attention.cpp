#include <gtest/gtest.h>
#include "attention.h"
#include "matmul.h"

// Attention forward call test function.
TEST(AttentionTest, forward_call) {
    // (1, 10, 2)
    float x[20] = {0.0, 1.1, -0.2, 3.3, 2.4, 1.5, 0.6, 2.7, 0.8, 0.65,
                   2.12, 6.78, 2.2, 9.1, 3.4, 1.55, -1.6, -2.7, -0.08, -0.65};

    // (2, 6)
    float w[12] = {0.12, -1.2, -0.7, 1.0, -1.3, 1.45,
                   0.08, 0.36, 1.6, -0.34, 0.87, 0.25};

    // (6)
    float bias[6] = {0.02, 0.03, 0.05, -0.02, -0.03, -0.01};

    // (1, 10, 6)
    float qkv_proj[60] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};
    // (1, 2, 10, 10)
    float preattn[200] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // (1, 2, 10, 10)
    float attn[200] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // (1, 10, 2)
    float y[20] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // y_truth is pytorch tensor output.
    /* Python code

    torch.set_printoptions(precision=6)
    x = [0.0, 1.1, -0.2, 3.3, 2.4, 1.5, 0.6, 2.7, 0.8, 0.65,
         2.12, 6.78, 2.2, 9.1, 3.4, 1.55, -1.6, -2.7, -0.08, -0.65]
    x = torch.tensor(x, requires_grad=True)
    x = torch.tensor(x, dtype=torch.float32).view(1, 10, 2)
    x = x.requires_grad_()
    weight = torch.tensor([0.12, -1.2, -0.7, 1.0, -1.3, 1.45,
                           0.08, 0.36, 1.6, -0.34, 0.87, 0.25], requires_grad=True)
    weight = nn.Parameter(weight.view(2, 6))
    bias = torch.tensor([0.02, 0.03, 0.05, -0.02, -0.03, -0.01], requires_grad=True)
    bias = nn.Parameter(bias.view(6))

    qkv_proj = x@weight + bias
    print(qkv_proj)

    query, key, value = torch.chunk(qkv_proj, 3, dim=-1)
    query = query.view(1, 10, 2, 1).transpose(1, 2)
    key = key.view(1, 10, 2, 1).transpose(1, 2)
    value = value.view(1, 10, 2, 1).transpose(1, 2)

    preattn = torch.matmul(query, key.transpose(-1, -2))
    preattn /= math.sqrt(1)
    maxval = torch.max(preattn)
    print(preattn)

    preattn -= maxval
    attn = nn.functional.softmax(preattn, dim=-1)
    print(attn)

    y = torch.matmul(attn, value).transpose(1, 2).contiguous().view(1, 10, -1)
    print(y)
    */
    float qkv_proj_truth[60] = {0.108000,  0.426000,  1.810000, -0.394000,  0.927000,  0.265000,
                                0.260000,  1.458000,  5.470000, -1.342000,  3.101000,  0.525000,
                                0.428000, -2.310000,  0.770000,  1.870000, -1.845000,  3.845000,
                                0.308000,  0.282000,  3.950000, -0.338000,  1.539000,  1.535000,
                                0.168000, -0.696000,  0.530000,  0.559000, -0.504500,  1.312500,
                                0.816800, -0.073200,  9.414001, -0.205200,  3.112600,  4.759000,
                                1.012000,  0.666000, 13.070001, -0.914000,  5.027000,  5.455000,
                                0.552000, -3.492000,  0.150000,  2.853000, -3.101500,  5.307500,
                                -0.388000,  0.978000, -3.150000, -0.702000, -0.299000, -3.005000,
                                -0.041600, -0.108000, -0.934000,  0.121000, -0.491500, -0.288500};
    float preattn_truth[200] = {1.954800e-01,  5.907600e-01,  8.316000e-02,  4.266000e-01, 5.723999e-02,  1.016712e+00,  1.411560e+00,  1.619999e-02, -3.402000e-01, -1.008720e-01,
                                4.706000e-01,  1.422200e+00,  2.002000e-01,  1.027000e+00, 1.378000e-01,  2.447640e+00,  3.398200e+00,  3.899997e-02, -8.190001e-01, -2.428400e-01,
                                7.746801e-01,  2.341160e+00,  3.295600e-01,  1.690600e+00, 2.268400e-01,  4.029192e+00,  5.593961e+00,  6.419996e-02, -1.348200e+00, -3.997520e-01,
                                5.574801e-01,  1.684760e+00,  2.371600e-01,  1.216600e+00, 1.632400e-01,  2.899513e+00,  4.025560e+00,  4.619997e-02, -9.702002e-01, -2.876720e-01,
                                3.040800e-01,  9.189600e-01,  1.293600e-01,  6.636000e-01, 8.904000e-02,  1.581552e+00,  2.195760e+00,  2.519998e-02, -5.292001e-01, -1.569120e-01,
                                1.478408e+00,  4.467896e+00,  6.289361e-01,  3.226360e+00, 4.329040e-01,  7.689355e+00,  1.067558e+01,  1.225199e-01, -2.572920e+00, -7.628912e-01,
                                1.831720e+00,  5.535640e+00,  7.792400e-01,  3.997400e+00, 5.363600e-01,  9.526968e+00,  1.322684e+01,  1.517999e-01, -3.187800e+00, -9.452079e-01,
                                9.991200e-01,  3.019440e+00,  4.250400e-01,  2.180400e+00, 2.925600e-01,  5.196528e+00,  7.214640e+00,  8.279994e-02, -1.738800e+00, -5.155680e-01,
                                -7.022800e-01, -2.122360e+00, -2.987600e-01, -1.532600e+00, -2.056400e-01, -3.652632e+00, -5.071160e+00, -5.819996e-02, 1.222200e+00,  3.623920e-01,
                                -7.529600e-02, -2.275520e-01, -3.203200e-02, -1.643200e-01, -2.204800e-02, -3.916224e-01, -5.437120e-01, -6.239995e-03, 1.310400e-01,  3.885439e-02,
                                -1.678440e-01, -5.716920e-01,  7.966201e-01, -1.439880e-01, 2.381340e-01, -8.741529e-02, -3.893640e-01,  1.215378e+00, -2.990520e-01,  5.154601e-02,
                                -5.744520e-01, -1.956636e+00,  2.726460e+00, -4.928041e-01, 8.150221e-01, -2.991819e-01, -1.332612e+00,  4.159675e+00, -1.023516e+00,  1.764180e-01,
                                9.101401e-01,  3.100020e+00, -4.319701e+00,  7.807801e-01, -1.291290e+00,  4.740125e-01,  2.111340e+00, -6.590431e+00, 1.621620e+00, -2.795101e-01,
                                -1.111080e-01, -3.784440e-01,  5.273401e-01, -9.531602e-02, 1.576380e-01, -5.786647e-02, -2.577480e-01,  8.045461e-01, -1.979640e-01,  3.412201e-02,
                                2.742240e-01,  9.340321e-01, -1.301520e+00,  2.352481e-01, -3.890641e-01,  1.428194e-01,  6.361441e-01, -1.985688e+00, 4.885920e-01, -8.421601e-02,
                                2.884069e-02,  9.823402e-02, -1.368835e-01,  2.474151e-02, -4.091864e-02,  1.502060e-02,  6.690454e-02, -2.088388e-01, 5.138620e-02, -8.857166e-03,
                                -2.624041e-01, -8.937722e-01,  1.245420e+00, -2.251081e-01, 3.722941e-01, -1.366634e-01, -6.087241e-01,  1.900098e+00, -4.675321e-01,  8.058602e-02,
                                1.375848e+00,  4.686265e+00, -6.530041e+00,  1.180296e+00, -1.952028e+00,  7.165592e-01,  3.191689e+00, -9.962678e+00, 2.451384e+00, -4.225321e-01,
                                -3.853320e-01, -1.312476e+00,  1.828860e+00, -3.305640e-01, 5.467020e-01, -2.006858e-01, -8.938920e-01,  2.790234e+00, -6.865560e-01,  1.183380e-01,
                                4.255200e-02,  1.449360e-01, -2.019600e-01,  3.650400e-02, -6.037200e-02,  2.216162e-02,  9.871200e-02, -3.081240e-01, 7.581599e-02, -1.306800e-02};
    float attn_truth[200] = {7.506742e-02, 1.114601e-01, 6.709213e-02, 9.458575e-02, 6.537539e-02, 1.706506e-01, 2.532726e-01, 6.274672e-02, 4.393476e-02, 5.581453e-02,
                             2.929708e-02, 7.587504e-02, 2.235584e-02, 5.110524e-02, 2.100347e-02, 2.115641e-01, 5.473496e-01, 1.902754e-02, 8.067853e-03, 1.435428e-02,
                             6.241777e-03, 2.989662e-02, 3.999402e-03, 1.559866e-02, 3.608978e-03, 1.617056e-01, 7.732059e-01, 3.067261e-03, 7.470560e-04, 1.928675e-03,
                             1.955257e-02, 6.036363e-02, 1.419353e-02, 3.779690e-02, 1.318220e-02, 2.033928e-01, 6.271508e-01, 1.172621e-02, 4.243660e-03, 8.397673e-03,
                             5.565375e-02, 1.029279e-01, 4.673202e-02, 7.973188e-02, 4.488526e-02, 1.996610e-01, 3.690121e-01, 4.210934e-02, 2.418830e-02, 3.509847e-02,
                             9.619922e-05, 1.912009e-03, 4.113869e-05, 5.524559e-04, 3.381544e-05, 4.792386e-02, 9.494039e-01, 2.479229e-05, 1.673793e-06, 1.022793e-05,
                             1.097262e-05, 4.455560e-04, 3.830220e-06, 9.568695e-05, 3.004293e-06, 2.411648e-02, 9.753217e-01, 2.045174e-06, 7.250369e-08, 6.828193e-07,
                             1.722622e-03, 1.298985e-02, 9.702202e-04, 5.613236e-03, 8.498352e-04, 1.145780e-01, 8.620969e-01, 6.890286e-04, 1.114620e-04, 3.787647e-04,
                             6.046469e-02, 1.461399e-02, 9.052075e-02, 2.635716e-02, 9.935505e-02, 3.163588e-03, 7.658104e-04, 1.151390e-01, 4.142791e-01, 1.753409e-01,
                             1.036388e-01, 8.900171e-02, 1.082211e-01, 9.481125e-02, 1.093069e-01, 7.553419e-02, 6.487720e-02, 1.110486e-01, 1.273893e-01, 1.161709e-01,
                             6.751662e-02, 4.508389e-02, 1.771218e-01, 6.914666e-02, 1.013269e-01, 7.317120e-02, 5.410103e-02, 2.692379e-01, 5.921443e-02, 8.407957e-02,
                             6.587926e-03, 1.653765e-03, 1.787792e-01, 7.148385e-03, 2.643565e-02, 8.675553e-03, 3.086627e-03, 7.494695e-01, 4.204583e-03, 1.395879e-02,
                             5.800017e-02, 5.181819e-01, 3.105547e-04, 5.096228e-02, 6.417417e-03, 3.749915e-02, 1.927987e-01, 3.206070e-05, 1.181466e-01, 1.765105e-02,
                             8.017312e-02, 6.136578e-02, 1.518110e-01, 8.144926e-02, 1.048923e-01, 8.455735e-02, 6.923790e-02, 2.003053e-01, 7.350345e-02, 9.270465e-02,
                             1.114411e-01, 2.155740e-01, 2.305197e-02, 1.071810e-01, 5.740939e-02, 9.771852e-02, 1.600387e-01, 1.162995e-02, 1.380842e-01, 7.787115e-02,
                             1.036592e-01, 1.111079e-01, 8.782832e-02, 1.032351e-01, 9.667447e-02, 1.022364e-01, 1.076810e-01, 8.173066e-02, 1.060227e-01, 9.982423e-02, 
                             4.601709e-02, 2.447483e-02, 2.078544e-01, 4.776576e-02, 8.680912e-02, 5.218285e-02, 3.254727e-02, 4.000206e-01, 3.748291e-02, 6.484526e-02,
                             2.563066e-02, 7.021917e-01, 9.446601e-06, 2.107816e-02, 9.193515e-04, 1.325667e-02, 1.575322e-01, 3.051410e-07, 7.513797e-02, 4.243589e-03,
                             2.364911e-02, 9.357530e-03, 2.164842e-01, 2.498046e-02, 6.006095e-02, 2.844499e-02, 1.422165e-02, 5.661687e-01, 1.749826e-02, 3.913413e-02,
                             1.051682e-01, 1.165062e-01, 8.235584e-02, 1.045340e-01, 9.488226e-02, 1.030455e-01, 1.112434e-01, 7.406073e-02, 1.087254e-01, 9.947843e-02};
    float y_truth[20] = {1.973216, 2.831853, 3.630815, 4.754962, 4.492849, 1.245482, 3.974648, 2.495470, 2.706016, 1.433586,
                         4.928514, 1.869183, 4.979530, 3.429150, 4.736339, 1.104455, -0.628659, 4.114753, 0.384810, 1.825571};
    float tolerance = 5e-6;

    matmul_forward(x, qkv_proj, w, bias, 1, 10, 2, 6);
    attention_forward(qkv_proj, preattn, attn, y, 1, 10, 2, 2);
    for(int i=0; i<60; ++i){
        EXPECT_NEAR(qkv_proj[i], qkv_proj_truth[i], tolerance);
    }
    for(int i=0; i<200; ++i){
        EXPECT_NEAR(preattn[i], preattn_truth[i], tolerance);
    }
    for(int i=0; i<200; ++i){
        EXPECT_NEAR(attn[i], attn_truth[i], tolerance);
    }
    for(int i=0; i<20; ++i){
        EXPECT_NEAR(y[i], y_truth[i], tolerance);
    }
}


int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}