#include <gtest/gtest.h>
#include "attention.h"
#include "matmul.h"

// Attention forward call test function.
TEST(AttentionTest, forward_call) {
    // (1, 10, 2)
    float x[20] = {0.0, 1.1, -0.2, 3.3, 2.4, 1.5, 0.6, 2.7, 0.8, 0.65,
                   2.12, 6.78, 2.2, 9.1, 3.4, 1.55, -1.6, -2.7, -0.08, -0.65};

    // (2, 6)
    float w[12] = {0.12, -1.2, -0.7, 1.0, -1.3, 1.45,
                   0.08, 0.36, 1.6, -0.34, 0.87, 0.25};

    // (6)
    float bias[6] = {0.02, 0.03, 0.05, -0.02, -0.03, -0.01};

    // (1, 10, 6)
    float qkv_proj[60] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};
    // (1, 2, 10, 10)
    float preattn[200] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // (1, 2, 10, 10)
    float attn[200] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // (1, 10, 2)
    float y[20] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // y_truth is pytorch tensor output.
    /* Python code

    torch.set_printoptions(precision=6)
    x = [0.0, 1.1, -0.2, 3.3, 2.4, 1.5, 0.6, 2.7, 0.8, 0.65,
         2.12, 6.78, 2.2, 9.1, 3.4, 1.55, -1.6, -2.7, -0.08, -0.65]
    x = torch.tensor(x, dtype=torch.float32).view(1, 10, 2)
    x = x.requires_grad_()
    weight = torch.tensor([0.12, -1.2, -0.7, 1.0, -1.3, 1.45,
                           0.08, 0.36, 1.6, -0.34, 0.87, 0.25], requires_grad=True)
    weight = nn.Parameter(weight.view(2, 6))
    bias = torch.tensor([0.02, 0.03, 0.05, -0.02, -0.03, -0.01], requires_grad=True)
    bias = nn.Parameter(bias.view(6))

    qkv_proj = x@weight + bias
    print(qkv_proj)

    query, key, value = torch.chunk(qkv_proj, 3, dim=-1)
    query = query.view(1, 10, 2, 1).transpose(1, 2)
    key = key.view(1, 10, 2, 1).transpose(1, 2)
    value = value.view(1, 10, 2, 1).transpose(1, 2)

    preattn = torch.matmul(query, key.transpose(-1, -2))
    preattn /= math.sqrt(1)
    maxval = torch.max(preattn)
    print(preattn)

    preattn -= maxval
    attn = nn.functional.softmax(preattn, dim=-1)
    print(attn)

    y = torch.matmul(attn, value).transpose(1, 2).contiguous().view(1, 10, -1)
    print(y)
    */
    float qkv_proj_truth[60] = {0.108000,  0.426000,  1.810000, -0.394000,  0.927000,  0.265000,
                                0.260000,  1.458000,  5.470000, -1.342000,  3.101000,  0.525000,
                                0.428000, -2.310000,  0.770000,  1.870000, -1.845000,  3.845000,
                                0.308000,  0.282000,  3.950000, -0.338000,  1.539000,  1.535000,
                                0.168000, -0.696000,  0.530000,  0.559000, -0.504500,  1.312500,
                                0.816800, -0.073200,  9.414001, -0.205200,  3.112600,  4.759000,
                                1.012000,  0.666000, 13.070001, -0.914000,  5.027000,  5.455000,
                                0.552000, -3.492000,  0.150000,  2.853000, -3.101500,  5.307500,
                                -0.388000,  0.978000, -3.150000, -0.702000, -0.299000, -3.005000,
                                -0.041600, -0.108000, -0.934000,  0.121000, -0.491500, -0.288500};
    float preattn_truth[200] = {1.954800e-01,  5.907600e-01,  8.316000e-02,  4.266000e-01, 5.723999e-02,  1.016712e+00,  1.411560e+00,  1.619999e-02, -3.402000e-01, -1.008720e-01,
                                4.706000e-01,  1.422200e+00,  2.002000e-01,  1.027000e+00, 1.378000e-01,  2.447640e+00,  3.398200e+00,  3.899997e-02, -8.190001e-01, -2.428400e-01,
                                7.746801e-01,  2.341160e+00,  3.295600e-01,  1.690600e+00, 2.268400e-01,  4.029192e+00,  5.593961e+00,  6.419996e-02, -1.348200e+00, -3.997520e-01,
                                5.574801e-01,  1.684760e+00,  2.371600e-01,  1.216600e+00, 1.632400e-01,  2.899513e+00,  4.025560e+00,  4.619997e-02, -9.702002e-01, -2.876720e-01,
                                3.040800e-01,  9.189600e-01,  1.293600e-01,  6.636000e-01, 8.904000e-02,  1.581552e+00,  2.195760e+00,  2.519998e-02, -5.292001e-01, -1.569120e-01,
                                1.478408e+00,  4.467896e+00,  6.289361e-01,  3.226360e+00, 4.329040e-01,  7.689355e+00,  1.067558e+01,  1.225199e-01, -2.572920e+00, -7.628912e-01,
                                1.831720e+00,  5.535640e+00,  7.792400e-01,  3.997400e+00, 5.363600e-01,  9.526968e+00,  1.322684e+01,  1.517999e-01, -3.187800e+00, -9.452079e-01,
                                9.991200e-01,  3.019440e+00,  4.250400e-01,  2.180400e+00, 2.925600e-01,  5.196528e+00,  7.214640e+00,  8.279994e-02, -1.738800e+00, -5.155680e-01,
                                -7.022800e-01, -2.122360e+00, -2.987600e-01, -1.532600e+00, -2.056400e-01, -3.652632e+00, -5.071160e+00, -5.819996e-02, 1.222200e+00,  3.623920e-01,
                                -7.529600e-02, -2.275520e-01, -3.203200e-02, -1.643200e-01, -2.204800e-02, -3.916224e-01, -5.437120e-01, -6.239995e-03, 1.310400e-01,  3.885439e-02,
                                -1.678440e-01, -5.716920e-01,  7.966201e-01, -1.439880e-01, 2.381340e-01, -8.741529e-02, -3.893640e-01,  1.215378e+00, -2.990520e-01,  5.154601e-02,
                                -5.744520e-01, -1.956636e+00,  2.726460e+00, -4.928041e-01, 8.150221e-01, -2.991819e-01, -1.332612e+00,  4.159675e+00, -1.023516e+00,  1.764180e-01,
                                9.101401e-01,  3.100020e+00, -4.319701e+00,  7.807801e-01, -1.291290e+00,  4.740125e-01,  2.111340e+00, -6.590431e+00, 1.621620e+00, -2.795101e-01,
                                -1.111080e-01, -3.784440e-01,  5.273401e-01, -9.531602e-02, 1.576380e-01, -5.786647e-02, -2.577480e-01,  8.045461e-01, -1.979640e-01,  3.412201e-02,
                                2.742240e-01,  9.340321e-01, -1.301520e+00,  2.352481e-01, -3.890641e-01,  1.428194e-01,  6.361441e-01, -1.985688e+00, 4.885920e-01, -8.421601e-02,
                                2.884069e-02,  9.823402e-02, -1.368835e-01,  2.474151e-02, -4.091864e-02,  1.502060e-02,  6.690454e-02, -2.088388e-01, 5.138620e-02, -8.857166e-03,
                                -2.624041e-01, -8.937722e-01,  1.245420e+00, -2.251081e-01, 3.722941e-01, -1.366634e-01, -6.087241e-01,  1.900098e+00, -4.675321e-01,  8.058602e-02,
                                1.375848e+00,  4.686265e+00, -6.530041e+00,  1.180296e+00, -1.952028e+00,  7.165592e-01,  3.191689e+00, -9.962678e+00, 2.451384e+00, -4.225321e-01,
                                -3.853320e-01, -1.312476e+00,  1.828860e+00, -3.305640e-01, 5.467020e-01, -2.006858e-01, -8.938920e-01,  2.790234e+00, -6.865560e-01,  1.183380e-01,
                                4.255200e-02,  1.449360e-01, -2.019600e-01,  3.650400e-02, -6.037200e-02,  2.216162e-02,  9.871200e-02, -3.081240e-01, 7.581599e-02, -1.306800e-02};
    float attn_truth[200] = {7.506742e-02, 1.114601e-01, 6.709213e-02, 9.458575e-02, 6.537539e-02, 1.706506e-01, 2.532726e-01, 6.274672e-02, 4.393476e-02, 5.581453e-02,
                             2.929708e-02, 7.587504e-02, 2.235584e-02, 5.110524e-02, 2.100347e-02, 2.115641e-01, 5.473496e-01, 1.902754e-02, 8.067853e-03, 1.435428e-02,
                             6.241777e-03, 2.989662e-02, 3.999402e-03, 1.559866e-02, 3.608978e-03, 1.617056e-01, 7.732059e-01, 3.067261e-03, 7.470560e-04, 1.928675e-03,
                             1.955257e-02, 6.036363e-02, 1.419353e-02, 3.779690e-02, 1.318220e-02, 2.033928e-01, 6.271508e-01, 1.172621e-02, 4.243660e-03, 8.397673e-03,
                             5.565375e-02, 1.029279e-01, 4.673202e-02, 7.973188e-02, 4.488526e-02, 1.996610e-01, 3.690121e-01, 4.210934e-02, 2.418830e-02, 3.509847e-02,
                             9.619922e-05, 1.912009e-03, 4.113869e-05, 5.524559e-04, 3.381544e-05, 4.792386e-02, 9.494039e-01, 2.479229e-05, 1.673793e-06, 1.022793e-05,
                             1.097262e-05, 4.455560e-04, 3.830220e-06, 9.568695e-05, 3.004293e-06, 2.411648e-02, 9.753217e-01, 2.045174e-06, 7.250369e-08, 6.828193e-07,
                             1.722622e-03, 1.298985e-02, 9.702202e-04, 5.613236e-03, 8.498352e-04, 1.145780e-01, 8.620969e-01, 6.890286e-04, 1.114620e-04, 3.787647e-04,
                             6.046469e-02, 1.461399e-02, 9.052075e-02, 2.635716e-02, 9.935505e-02, 3.163588e-03, 7.658104e-04, 1.151390e-01, 4.142791e-01, 1.753409e-01,
                             1.036388e-01, 8.900171e-02, 1.082211e-01, 9.481125e-02, 1.093069e-01, 7.553419e-02, 6.487720e-02, 1.110486e-01, 1.273893e-01, 1.161709e-01,
                             6.751662e-02, 4.508389e-02, 1.771218e-01, 6.914666e-02, 1.013269e-01, 7.317120e-02, 5.410103e-02, 2.692379e-01, 5.921443e-02, 8.407957e-02,
                             6.587926e-03, 1.653765e-03, 1.787792e-01, 7.148385e-03, 2.643565e-02, 8.675553e-03, 3.086627e-03, 7.494695e-01, 4.204583e-03, 1.395879e-02,
                             5.800017e-02, 5.181819e-01, 3.105547e-04, 5.096228e-02, 6.417417e-03, 3.749915e-02, 1.927987e-01, 3.206070e-05, 1.181466e-01, 1.765105e-02,
                             8.017312e-02, 6.136578e-02, 1.518110e-01, 8.144926e-02, 1.048923e-01, 8.455735e-02, 6.923790e-02, 2.003053e-01, 7.350345e-02, 9.270465e-02,
                             1.114411e-01, 2.155740e-01, 2.305197e-02, 1.071810e-01, 5.740939e-02, 9.771852e-02, 1.600387e-01, 1.162995e-02, 1.380842e-01, 7.787115e-02,
                             1.036592e-01, 1.111079e-01, 8.782832e-02, 1.032351e-01, 9.667447e-02, 1.022364e-01, 1.076810e-01, 8.173066e-02, 1.060227e-01, 9.982423e-02, 
                             4.601709e-02, 2.447483e-02, 2.078544e-01, 4.776576e-02, 8.680912e-02, 5.218285e-02, 3.254727e-02, 4.000206e-01, 3.748291e-02, 6.484526e-02,
                             2.563066e-02, 7.021917e-01, 9.446601e-06, 2.107816e-02, 9.193515e-04, 1.325667e-02, 1.575322e-01, 3.051410e-07, 7.513797e-02, 4.243589e-03,
                             2.364911e-02, 9.357530e-03, 2.164842e-01, 2.498046e-02, 6.006095e-02, 2.844499e-02, 1.422165e-02, 5.661687e-01, 1.749826e-02, 3.913413e-02,
                             1.051682e-01, 1.165062e-01, 8.235584e-02, 1.045340e-01, 9.488226e-02, 1.030455e-01, 1.112434e-01, 7.406073e-02, 1.087254e-01, 9.947843e-02};
    float y_truth[20] = {1.973216, 2.831853, 3.630815, 4.754962, 4.492849, 1.245482, 3.974648, 2.495470, 2.706016, 1.433586,
                         4.928514, 1.869183, 4.979530, 3.429150, 4.736339, 1.104455, -0.628659, 4.114753, 0.384810, 1.825571};
    float tolerance = 5e-6;

    matmul_forward(x, qkv_proj, w, bias, 1, 10, 2, 6);
    attention_forward(qkv_proj, preattn, attn, y, 1, 10, 2, 2);
    for(int i=0; i<60; ++i){
        EXPECT_NEAR(qkv_proj[i], qkv_proj_truth[i], tolerance);
    }
    for(int i=0; i<200; ++i){
        EXPECT_NEAR(preattn[i], preattn_truth[i], tolerance);
    }
    for(int i=0; i<200; ++i){
        EXPECT_NEAR(attn[i], attn_truth[i], tolerance);
    }
    for(int i=0; i<20; ++i){
        EXPECT_NEAR(y[i], y_truth[i], tolerance);
    }
}

// Attention backward call test function.
TEST(AttentionTest, backward_call){
    // (1, 10, 2)
    float x[20] = {0.0, 1.1, -0.2, 3.3, 2.4, 1.5, 0.6, 2.7, 0.8, 0.65,
                   2.12, 6.78, 2.2, 9.1, 3.4, 1.55, -1.6, -2.7, -0.08, -0.65};

    // (2, 6)
    float w[12] = {0.12, -1.2, -0.7, 1.0, -1.3, 1.45,
                   0.08, 0.36, 1.6, -0.34, 0.87, 0.25};

    // (6)
    float bias[6] = {0.02, 0.03, 0.05, -0.02, -0.03, -0.01};

    // (1, 10, 6)
    float qkv_proj[60] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};
    // (1, 2, 10, 10)
    float preattn[200] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                          0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // (1, 2, 10, 10)
    float attn[200] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // (1, 10, 2)
    float y[20] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                   0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // derivatives
    float dy[20] = {1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0};

    float dattn[200] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};
    
    float dpreattn[200] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    float dqkv_proj[60] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                           0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};
    
    float dbias[6] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0};
    float dw[12] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};
    float dx[20] = {0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0};

    // y_truth is pytorch tensor output.
    /* Python code

    torch.set_printoptions(precision=6)
    x = [0.0, 1.1, -0.2, 3.3, 2.4, 1.5, 0.6, 2.7, 0.8, 0.65,
         2.12, 6.78, 2.2, 9.1, 3.4, 1.55, -1.6, -2.7, -0.08, -0.65]
    x = torch.tensor(x, dtype=torch.float32).view(1, 10, 2)
    x = x.requires_grad_()
    weight = torch.tensor([0.12, -1.2, -0.7, 1.0, -1.3, 1.45,
                           0.08, 0.36, 1.6, -0.34, 0.87, 0.25], requires_grad=True)
    weight = nn.Parameter(weight.view(2, 6))
    bias = torch.tensor([0.02, 0.03, 0.05, -0.02, -0.03, -0.01], requires_grad=True)
    bias = nn.Parameter(bias.view(6))

    qkv_proj = x@weight + bias
    qkv_proj.retain_grad()

    query, key, value = torch.chunk(qkv_proj, 3, dim=-1)
    query = query.view(1, 10, 2, 1).transpose(1, 2)
    key = key.view(1, 10, 2, 1).transpose(1, 2)
    value = value.view(1, 10, 2, 1).transpose(1, 2)

    preattn = torch.matmul(query, key.transpose(-1, -2))
    preattn /= math.sqrt(1)
    maxval = torch.max(preattn).item()

    preattn -= maxval
    preattn.retain_grad()
    attn = nn.functional.softmax(preattn, dim=-1)
    attn.retain_grad()

    y = torch.matmul(attn, value).transpose(1, 2).contiguous().view(1, 10, -1)
    y.sum().backward()

    print(attn.grad)
    print(preattn.grad)
    print(qkv_proj.grad)
    print(weight.grad)
    print(bias.grad)
    print(x.grad)
    */
    float dx_truth[20] = {-0.929481, 2.159416, 4.235065, 0.963828, 1.274682, 0.779669, -1.726415, 1.679658 ,1.059755, 1.535677,
                          -2.528716, 1.296117, -14.002751, 9.090649, 5.078907, 0.302388, 0.278860, 0.545277, -0.535519, 1.585899};
    float dw_truth[12] = {22.826756, 7.129204, 1.256835, -9.002916, 15.992939, 13.249347, 
                          69.551064, 37.316669, 6.380577, -41.965115, 60.079193, 23.971653};
    float dbias_truth[6] = {5.129218e+01, 1.287556e+01, 5.662441e-07, 2.980232e-07, 9.999999e+00, 1.000000e+01};

    float dqkv_proj_truth[60] = {12.434584, 2.441547, -0.116406, -0.026361, 0.351746, 0.627843,
                                 8.166098, 0.867597, -0.070730,  2.278100, 0.499486, 1.805498,
                                 2.834660, 0.100990, -0.082535, -0.173825, 0.354130, 1.125607,
                                 6.200247, 2.205944, -0.134427, -0.284636, 0.406248, 0.617481,
                                 11.690895, 0.298205, -0.093559, -0.507862, 0.357604, 0.635828,
                                 0.375355, 1.296937, -0.375905, -0.575734, 1.212290, 0.600788,
                                 0.175277, 2.451569,  1.053491, -4.603874, 5.422456, 0.902488,
                                 1.320195, 0.131307, -0.020890, 2.127333, 0.365580, 2.352656,
                                 0.288493, 1.871491, -0.088037, 2.168127, 0.622963, 0.738021,
                                 7.806379, 1.209975, -0.071001, -0.401268, 0.407495, 0.593791};

    float dpreattn_truth[200] = {-7.853673e-02, 1.257029e-01, -2.561722e-01, -4.107065e-02, -1.619816e-01, 1.944367e-01, 7.734398e-01, -3.184218e-01, -9.982927e-02, -1.375670e-01,
                                 -7.921387e-02, -4.019972e-02, -1.224165e-01, -1.069027e-01, -8.685598e-02, -1.096356e-01, 7.642013e-01, -1.280994e-01, -3.170517e-02, -5.917284e-02,
                                 -2.225723e-02, -4.161157e-02, -2.534761e-02, -4.607609e-02, -1.803532e-02, -2.231940e-01, 4.130088e-01, -2.329385e-02, -3.579780e-03, -9.613186e-03,
                                 -5.958932e-02, -5.273652e-02, -8.260135e-02, -9.205993e-02, -5.904500e-02, -1.753341e-01, 6.599839e-01, -8.297639e-02, -1.813591e-02, -3.750525e-02,
                                 -9.900892e-02, 4.065489e-02, -2.126782e-01, -9.304839e-02, -1.441048e-01, 8.117904e-02, 8.564711e-01, -2.445506e-01, -7.268622e-02, -1.122279e-01,
                                 -3.849425e-04, -3.494223e-03, -2.786535e-04, -1.872557e-03, -1.837198e-04, -8.702558e-02, 9.350294e-02, -1.990825e-04, -8.749779e-06, -5.543554e-05,
                                 -4.446687e-05, -8.369904e-04, -2.613945e-05, -3.292139e-04, -1.647564e-05, -4.502377e-02, 4.629814e-02, -1.652711e-05, -3.827129e-07, -3.735725e-06,
                                 -6.562049e-03, -2.124280e-02, -6.385348e-03, -1.794742e-02, -4.453849e-03, -1.860447e-01, 2.505782e-01, -5.400495e-03, -5.612487e-04, -1.980121e-03,
                                 9.406246e-02, 5.450521e-02, -1.101041e-01, 5.713335e-02, 1.233585e-02, 1.183581e-02, 4.331163e-03, -2.847203e-01, 1.365709e-01, 2.404963e-02,
                                 5.619197e-02, 2.417456e-01, -2.413124e-01, 1.094302e-01, -9.720770e-02, 2.060415e-01, 3.011723e-01, -3.871498e-01, -8.711001e-02, -1.018017e-01,
                                 -1.733052e-01, -1.040019e-01, 1.794506e-01, -8.967303e-02, -1.539513e-01, 1.410117e-01, 1.419150e-01, 6.665380e-01, -3.456259e-01, -2.623579e-01,
                                 -2.957953e-02, -6.995363e-03, -1.626821e-01, -2.301752e-02, -9.100371e-02, 3.503478e-05, 2.160758e-03, 4.141107e-01, -3.262740e-02, -7.040060e-02,
                                 -5.686814e-02, -3.733409e-01, 8.072925e-04, 1.475449e-02, 4.300819e-04,  1.317539e-01, 8.115894e-01, 1.302311e-04, -5.021800e-01, -2.707640e-02,
                                 -1.788237e-01, -1.209194e-01, 2.048735e-01, -7.822955e-02, -1.240844e-01, 1.913981e-01, 2.049117e-01, 5.632644e-01, -4.043035e-01, -2.580869e-01,
                                 -1.302285e-01, -1.958675e-01, 5.558785e-02, 1.086965e-02, -6.951473e-03, 3.249545e-01, 6.435817e-01, 4.505342e-02, -6.128988e-01, -1.341008e-01,
                                 -1.662883e-01, -1.493493e-01, 1.735327e-01, -3.449939e-02, -5.381701e-02, 2.954446e-01, 3.861242e-01, 2.810159e-01, -5.167742e-01, -2.153890e-01,
                                 -1.456050e-01, -7.107857e-02, 8.643627e-02, -9.047551e-02, -1.837445e-01, 6.939534e-02, 6.593589e-02, 7.513786e-01, -2.411707e-01, -2.410720e-01,
                                 -2.151579e-02, -4.068886e-01, 2.588884e-05, 9.075096e-03, 1.912665e-04, 4.844710e-02, 6.853510e-01, 1.282521e-06, -3.087761e-01, -5.911129e-03,
                                 -9.104323e-02, -3.359122e-02, -5.839727e-02, -6.444342e-02, -1.683060e-01, 1.832559e-02, 1.906051e-02, 6.752958e-01, -1.245833e-01, -1.723175e-01,
                                 -1.641224e-01, -1.515246e-01, 1.663118e-01, -3.037453e-02, -4.868131e-02,  3.022766e-01, 4.037502e-01, 2.578742e-01, -5.252057e-01, -2.103045e-01};

    float dattn_truth[200] = {0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.927000,  3.101000, -1.845000,  1.539000, -0.504500,  3.112600, 5.027000, -3.101500, -0.299000, -0.491500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500,
                              0.265000,  0.525000,  3.845000,  1.535000,  1.312500,  4.759000, 5.455000,  5.307500, -3.005000, -0.288500};
    // Set slightly higher tolerance level to account for different scales in different layers(10s, 1s, 0.xx) => This is due to the absence of normalization.
    float tolerance = 5e-5;

    matmul_forward(x, qkv_proj, w, bias, 1, 10, 2, 6);
    attention_forward(qkv_proj, preattn, attn, y, 1, 10, 2, 2);
    attention_backward(qkv_proj, attn, dqkv_proj, dpreattn, dattn, dy, 1, 10, 2, 2);
    matmul_backward(x, w, dx, dw, dbias, dqkv_proj, 1, 10, 2, 6);
    for(int i=0; i<200; ++i){
        EXPECT_NEAR(dattn[i], dattn_truth[i], tolerance);
    }
    for(int i=0; i<200; ++i){
        EXPECT_NEAR(dpreattn[i], dpreattn_truth[i], tolerance);
    }
    for(int i=0; i<60; ++i){
        EXPECT_NEAR(dqkv_proj[i], dqkv_proj_truth[i], tolerance);
    }
    for(int i=0; i<6; ++i){
        EXPECT_NEAR(dbias[i], dbias_truth[i], tolerance);
    }
    for(int i=0; i<12; ++i){
        EXPECT_NEAR(dw[i], dw_truth[i], tolerance);
    }
    for(int i=0; i<20; ++i){
        EXPECT_NEAR(dx[i], dx_truth[i], tolerance);
    }
}


int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}